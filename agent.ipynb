{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddeec8ff",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e96684b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Installation complete.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-adk -q\n",
    "%pip install litellm -q\n",
    "\n",
    "print(\"Installation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009e615d",
   "metadata": {},
   "source": [
    "### Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84dddce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# @title Import necessary libraries\n",
    "import os\n",
    "import asyncio\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For multi-model support\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c0d956",
   "metadata": {},
   "source": [
    "### Configuring API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92fbe0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Keys Set:\n",
      "Google API Key set: Yes\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "\n",
    "# --- Verify Keys ---\n",
    "print(\"API Keys Set:\")\n",
    "print(f\"Google API Key set: {'Yes' if os.environ.get('GOOGLE_API_KEY') and os.environ['GOOGLE_API_KEY'] != 'YOUR_GOOGLE_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
    "\n",
    "# Configure ADK to use API keys directly (not Vertex AI for this multi-model setup)\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"False\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914891c2",
   "metadata": {},
   "source": [
    "### Defining Model Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "636e4351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment configured.\n"
     ]
    }
   ],
   "source": [
    "MODEL_GEMINI_2_0_FLASH = \"gemini-2.0-flash\"\n",
    "\n",
    "# This seemed to work better\n",
    "MODEL_GEMINI_2_0_FLASH_EXP = \"gemini-2.0-flash-exp\"\n",
    "\n",
    "\n",
    "print(\"Environment configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5904637",
   "metadata": {},
   "source": [
    "# Building First Agent\n",
    "\n",
    "**Core Principles**\n",
    "\n",
    "- Agent: The underlying \"brain\" that communicates with the user and determines what to do depending on user requests\n",
    "- Tool: Python functions that gives the agent to perform specific tasks. We can have functions to check time, look up weather, send emails, etc. Tools should be detailed and very systematic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bbbf43",
   "metadata": {},
   "source": [
    "### Defining Tools\n",
    "\n",
    "**Key Concepts**: Docstrings are crucial, as good ones allow agents to better under **how** to use them and to understand:\n",
    "- what the tool does\n",
    "- when to use it\n",
    "- what arguments it requires\n",
    "- what information it returns\n",
    "\n",
    "**Best Practice**: Write clear, descriptive, and accurate docstring for tools. (There's a potential for ChatGPT to help write the docstrings, since they're capable of being descriptive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0f75b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather called for city: New York ---\n",
      "{'status': 'success', 'report': 'The weather in New York is sunny with a temperature of 25째C.'}\n",
      "--- Tool: get_weather called for city: Paris ---\n",
      "{'status': 'error', 'error_message': \"Sorry, I don't have weather information for 'Paris'.\"}\n"
     ]
    }
   ],
   "source": [
    "# Mock get_weather tool, with hardcoded answers\n",
    "def get_weather(city: str) -> dict:\n",
    "    \"\"\"Retrieves the current weather report for a specified city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city (e.g., \"New York\", \"London\", \"Tokyo\").\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the weather information.\n",
    "              Includes a 'status' key ('success' or 'error').\n",
    "              If 'success', includes a 'report' key with weather details.\n",
    "              If 'error', includes an 'error_message' key.\n",
    "    \"\"\"\n",
    "    print(f\"--- Tool: get_weather called for city: {city} ---\") # Log tool execution\n",
    "    city_normalized = city.lower().replace(\" \", \"\") # Basic normalization\n",
    "\n",
    "    # Mock weather database\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": {\"status\": \"success\", \"report\": \"The weather in New York is sunny with a temperature of 25째C.\"},\n",
    "        \"london\": {\"status\": \"success\", \"report\": \"It's cloudy in London with a temperature of 15째C.\"},\n",
    "        \"tokyo\": {\"status\": \"success\", \"report\": \"Tokyo is experiencing light rain and a temperature of 18째C.\"},\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return {\"status\": \"error\", \"error_message\": f\"Sorry, I don't have weather information for '{city}'.\"}\n",
    "\n",
    "# Example tool usage (optional test)\n",
    "print(get_weather(\"New York\"))\n",
    "print(get_weather(\"Paris\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd6cd32",
   "metadata": {},
   "source": [
    "# Defining Agents\n",
    "\n",
    "An orchestrator that facilitates interaction between the user and LLM and available tools\n",
    "\n",
    "For ADK, there's several key parameters for an agent:\n",
    "- `name`: A unique identifier for this agent\n",
    "- `model`: Specifies what model this agent should use. Different models may be more capable than others had doing certain tasks\n",
    "- `description`: A concise sumnmary of the agent's overall purpose, which is crucial later when other agents need to decide whether to delegate tasks to this agent.\n",
    "- `instruction`: Detailed guidance for the LLM on how to behave, its persona, its goals, and specifically how and when to utilize its assigned `tools`\n",
    "- `tools`: A list containing the actual Python tool functions that the agent is allowed to use\n",
    "\n",
    "**Best Practice**: Choose descriptive `name` and `description` values, since those are used internally by ADK and are vital for features like automic delegation\n",
    "\n",
    "**Note**: In a way, the agents are structured like a tree hierachy, where task are first passed to the root agent, then it gets sent to respective agents that are most suited for the task. An analogy can be like a company and how tasks are dealt with. The CEO sees a tasks, then it decides to pass it to a particular department, then the department leader pass to a subgroup to handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0094fd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'weather_agent_v1' created using model 'gemini-2.0-flash'.\n"
     ]
    }
   ],
   "source": [
    "# @title Define the Weather Agent\n",
    "# Use one of the model constants defined earlier\n",
    "AGENT_MODEL = MODEL_GEMINI_2_0_FLASH\n",
    "\n",
    "weather_agent = Agent(\n",
    "    name=\"weather_agent_v1\",\n",
    "    model=AGENT_MODEL, # Can be a string for Gemini or a LiteLlm object\n",
    "    description=\"Provides weather information for specific cities.\",\n",
    "    instruction=\"You are a helpful weather assistant. \"\n",
    "                \"When the user asks for the weather in a specific city, \"\n",
    "                \"use the 'get_weather' tool to find the information. \"\n",
    "                \"If the tool returns an error, inform the user politely. \"\n",
    "                \"If the tool is successful, present the weather report clearly.\",\n",
    "    tools=[get_weather], # Pass the function directly\n",
    ")\n",
    "\n",
    "print(f\"Agent '{weather_agent.name}' created using model '{AGENT_MODEL}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f394e0",
   "metadata": {},
   "source": [
    "### Setup Runner and Session Servicess\n",
    "\n",
    "This is to manage conversation and execute the agent, and has 2 components:\n",
    "\n",
    "- `SessionService`: Responsible for managing conversation history and state for different user and sessions. In the following, we'll use `InMemorySessionService`, a simple implementation that stores everything in memory, suitable for testing and simple applications. It also keeps track of messages exchanged\n",
    "- `Runner`: The engine that orchestrates the interaction flow. It takes user input, route it to the appropriate agent, manages calls to the LLM and tools based on the agent's logic, handles session updates via the `SessionService`, and yields events representing the process of the interaction\n",
    "\n",
    "In short, the `SessionService` manages conversation history for different users, and the `Runner` is the facilitator that direct the flow of user inputs, determining which sub-agents are the most appropriate for a particular task\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb979095",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object Session can't be used in 'await' expression",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m SESSION_ID \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession_001\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# Using a fixed ID for simplicity\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Create the specific session where the conversation will happen\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m session_service\u001b[38;5;241m.\u001b[39mcreate_session(\n\u001b[0;32m     15\u001b[0m     app_name\u001b[38;5;241m=\u001b[39mAPP_NAME,\n\u001b[0;32m     16\u001b[0m     user_id\u001b[38;5;241m=\u001b[39mUSER_ID,\n\u001b[0;32m     17\u001b[0m     session_id\u001b[38;5;241m=\u001b[39mSESSION_ID\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSession created: App=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAPP_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, User=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mUSER_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, Session=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSESSION_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# --- Runner ---\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Key Concept: Runner orchestrates the agent execution loop.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: object Session can't be used in 'await' expression"
     ]
    }
   ],
   "source": [
    "# @title Setup Session Service and Runner\n",
    "\n",
    "# --- Session Management ---\n",
    "# Key Concept: SessionService stores conversation history & state.\n",
    "# InMemorySessionService is simple, non-persistent storage for this tutorial.\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "# Define constants for identifying the interaction context\n",
    "APP_NAME = \"weather_tutorial_app\"\n",
    "USER_ID = \"user_1\"\n",
    "SESSION_ID = \"session_001\" # Using a fixed ID for simplicity\n",
    "\n",
    "# Create the specific session where the conversation will happen\n",
    "session = await session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID\n",
    ")\n",
    "print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
    "\n",
    "# --- Runner ---\n",
    "# Key Concept: Runner orchestrates the agent execution loop.\n",
    "runner = Runner(\n",
    "    agent=weather_agent, # The agent we want to run\n",
    "    app_name=APP_NAME,   # Associates runs with our app\n",
    "    session_service=session_service # Uses our session manager\n",
    ")\n",
    "print(f\"Runner created for agent '{runner.agent.name}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826cc2e1",
   "metadata": {},
   "source": [
    "Note: When looking at the above code, it seems like Runner is given an agent and a session. Thus the runner is specific to that particular session, as well as having access to that specific agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be6b7d",
   "metadata": {},
   "source": [
    "### Interacting with the Agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa22e137",
   "metadata": {},
   "source": [
    "We need a way to send messages to our agents and recieve its responses. Since LLM calls and tool execution can take time, ADK's `Runner` operates asynchronously. \n",
    "\n",
    "A helper function `call_agent_async` will be used to:\n",
    "- Takes a a user query string\n",
    "- Packages it into ADK `Content` format (Its expected input)\n",
    "- Calls `runner.run.async`, providing the user/session context and the new message\n",
    "- Iterates through the Event yielded by the runner. Events represent steps in the agent's execution (e.g. tool call requested, tool result recieved, intermediate LLM thought, final response)\n",
    "- Identifies and prints the final response event using `event.is_final_response()`\n",
    "\n",
    "**Purpose of `async`**: Interactions with LLMs and some tools are I/O-bound operations. Using `asyncio` allows the program to handle these operations efficiently without blocking execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f8accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "async def call_agent_async(query: str, runner, user_id, session_id) -> None:\n",
    "   \"\"\"Sends a query to the agent and prints the final response.\n",
    "   Args:\n",
    "      query (str): The user query to send to the agent.\n",
    "      runner (Runner): The Runner instance managing the agent.\n",
    "      user_id (str): The ID of the user making the request.\n",
    "      session_id (str): The ID of the session for this interaction.\n",
    "   \n",
    "   Returns:\n",
    "      None: This function does not return a value.\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "   print(f\"\\n>>> User Query: {query}\")\n",
    "\n",
    "   # Content can be think of message package that contains 1+ Parts (message, file, image, etc)\n",
    "   content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "\n",
    "   final_response_text = \"Agent did not produce a final response\"    # Default response\n",
    "\n",
    "   async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
    "\n",
    "      # Uncomment the line below to see *all* events during execution\n",
    "      # print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
    "\n",
    "      if event.is_final_response():\n",
    "\n",
    "         if event.content and event.content.parts:                   # If the the return message package is not empty\n",
    "            final_response_text = event.content.parts[0].text        # Extract the result response and set it\n",
    "         elif event.actions and event.actions.escalate:\n",
    "            final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"    # Error/escalation\n",
    "         \n",
    "         break    # Stops after final response is found\n",
    "         \n",
    "   print(f\"<<< Agent Response: {final_response_text}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21205683",
   "metadata": {},
   "source": [
    "### Running the Conversation\n",
    "\n",
    "Since `call_agent_async` is asynchronous, we don't want the output to mix the text between multiple agent calls. That's why we have the `await` keyword to tell python to wait until the response is fully done to move up to the next call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e474c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'call_agent_async' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m call_agent_async(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTell me the weather in New York\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m                                        runner\u001b[38;5;241m=\u001b[39mrunner,\n\u001b[0;32m     16\u001b[0m                                        user_id\u001b[38;5;241m=\u001b[39mUSER_ID,\n\u001b[0;32m     17\u001b[0m                                        session_id\u001b[38;5;241m=\u001b[39mSESSION_ID)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Execute the conversation using await in an async context (like Colab/Jupyter)\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m run_conversation()\n",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m, in \u001b[0;36mrun_conversation\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_conversation\u001b[39m():\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m call_agent_async(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the weather like in London?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m                                        runner\u001b[38;5;241m=\u001b[39mrunner,\n\u001b[0;32m      6\u001b[0m                                        user_id\u001b[38;5;241m=\u001b[39mUSER_ID,\n\u001b[0;32m      7\u001b[0m                                        session_id\u001b[38;5;241m=\u001b[39mSESSION_ID)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m call_agent_async(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow about Paris?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m                                        runner\u001b[38;5;241m=\u001b[39mrunner,\n\u001b[0;32m     11\u001b[0m                                        user_id\u001b[38;5;241m=\u001b[39mUSER_ID,\n\u001b[0;32m     12\u001b[0m                                        session_id\u001b[38;5;241m=\u001b[39mSESSION_ID) \u001b[38;5;66;03m# Expecting the tool's error message\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m call_agent_async(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTell me the weather in New York\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m                                        runner\u001b[38;5;241m=\u001b[39mrunner,\n\u001b[0;32m     16\u001b[0m                                        user_id\u001b[38;5;241m=\u001b[39mUSER_ID,\n\u001b[0;32m     17\u001b[0m                                        session_id\u001b[38;5;241m=\u001b[39mSESSION_ID)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'call_agent_async' is not defined"
     ]
    }
   ],
   "source": [
    "# @title Run the Initial Conversation\n",
    "\n",
    "async def run_conversation():\n",
    "    await call_agent_async(\"What is the weather like in London?\",\n",
    "                                       runner=runner,\n",
    "                                       user_id=USER_ID,\n",
    "                                       session_id=SESSION_ID)\n",
    "\n",
    "    await call_agent_async(\"How about Paris?\",\n",
    "                                       runner=runner,\n",
    "                                       user_id=USER_ID,\n",
    "                                       session_id=SESSION_ID) # Expecting the tool's error message\n",
    "\n",
    "    await call_agent_async(\"Tell me the weather in New York\",\n",
    "                                       runner=runner,\n",
    "                                       user_id=USER_ID,\n",
    "                                       session_id=SESSION_ID)\n",
    "\n",
    "# Execute the conversation using await in an async context (like Colab/Jupyter)\n",
    "await run_conversation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b6929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Global)",
   "language": "python",
   "name": "global-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
